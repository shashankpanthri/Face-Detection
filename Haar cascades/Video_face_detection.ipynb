{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most of the things we need here are the same as we used for images but I will still do everything again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The things that will be different will start after we make the function to detect faces and put rectange on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open cv for image processing and importing \n",
    "import cv2\n",
    "\n",
    "# for visualizing the images \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now import the main harrcascade xml file that actually has the pre-trained model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have the model we just have to make a function to make a rectangle where it detects a face.**\n",
    "\n",
    "The steps we will follow are:\n",
    "1. Make a copy of the image.\n",
    "2. use the **detectMultiScale** to detect the face with few arguments that are:\n",
    "    * the actual image.\n",
    "    \n",
    "    * minNeighbors : How many neighbours each window should have for the area in the window to be considered a face. This parameter controls how many rectangles (neighbours) need to be detected for the window to be labelled a face.\n",
    "    \n",
    "    * scaleFactor : The value is used to scale pyramid to detect faces at multiple scales in the image.\n",
    "\n",
    "3. At this point we have all the points for all the faces detected by the classifier in the image as tuples.\n",
    "4. Now we iterate through each of the tuples and \n",
    "5. make a rectange using these points in the tuples with color white and thickness 4.\n",
    "6. Finally, we return the new image with the rectangles made on top of detected faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(img):\n",
    "    \n",
    "    # make a copy of the image\n",
    "    face = img.copy()\n",
    "    \n",
    "    # the main detection line\n",
    "    face_rect = face_cascade.detectMultiScale(img, minNeighbors=5, scaleFactor=1.2)\n",
    "    \n",
    "    for (x,y,w,h) in face_rect:\n",
    "        \n",
    "        cv2.rectangle(face, (x,y), (x+w, y+h), (255,255,255), 4)\n",
    "\n",
    "    return face\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will do the things differently from the image one. Here we are using video which is nothing but a lot of images showing one after the other based on how many frames(images) are set to show in a second.**\n",
    "\n",
    "We can do two types of video i.e. from a webcam(live video) or from a video file already recorded.\n",
    "\n",
    "So the steps we need to do are:\n",
    "1. Make a video capture object using openCV. This will take the video as input. We can either give it a **path to a video** or just put **0 to for it to automatically detect from the default webcam that is present in the computer**.\n",
    "\n",
    "2. Make a while loop that will constantly do a certain things for us until we stop it. The things are:\n",
    "    * get the frames from the video one by one.\n",
    "    \n",
    "    * pass that frame to the face detection function.\n",
    "    \n",
    "    * show the frame using openCV.\n",
    "    \n",
    "    * Make a waitkey to break out of the while loop.\n",
    "    \n",
    "    * release the capture object after breaking out of the loop.\n",
    "    \n",
    "    * destroy all the windows after breaking out of the loop.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# the infinite while loop\n",
    "while True:\n",
    "    \n",
    "    # read frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # pass the frame to the function\n",
    "    frame = face_detection(frame)\n",
    "    \n",
    "    # display the resultant frame\n",
    "    cv2.imshow(\"face\", frame)\n",
    "    \n",
    "    \n",
    "    # make a waitkey that will wait for a second and break out of the loop if \"q\" is pressed.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#release the cap object\n",
    "cap.release()\n",
    "# destroy all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write this video file we are reading frame by frame by using a writer object. That will have around 6 lines of code added to this.\n",
    "\n",
    "The steps for that will be same as above with the added lines of:\n",
    "1. Get the frame width and height of the camera.\n",
    "2. Make a writer object with appropriate arguments.\n",
    "3. Write the frame we are reading after processing it.\n",
    "4. Release the writer object after breaking out of the while loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# get the frame width and height\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))   \n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# make the writer object\n",
    "writer = cv2.VideoWriter('face_detection_video.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 20, (width,height))\n",
    "\n",
    "# the infinite while loop\n",
    "while True:\n",
    "    \n",
    "    # read frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # pass the frame to the function\n",
    "    frame = face_detection(frame)\n",
    "    \n",
    "    # write the frame\n",
    "    writer.write(frame)\n",
    "    \n",
    "    # display the resultant frame\n",
    "    cv2.imshow(\"face\", frame)\n",
    "    \n",
    "    \n",
    "    # make a waitkey that will wait for a second and break out of the loop if \"q\" is pressed.\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#release the cap object\n",
    "cap.release()\n",
    "# release the writer object\n",
    "writer.release()\n",
    "# destroy the windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
